{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0af524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Import ds_utils ML evaluation functions\n",
    "from ds_utils.ml_eval import (\n",
    "    classification_summary,\n",
    "    regression_summary,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_calibration_curve,\n",
    "    plot_residuals,\n",
    "    plot_prediction_error,\n",
    "    plot_residual_distribution,\n",
    "    plot_feature_importance,\n",
    "    plot_learning_curve,\n",
    "    plot_validation_curve,\n",
    ")\n",
    "from ds_utils.plotting import apply_corporate_style\n",
    "\n",
    "apply_corporate_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df1b4e",
   "metadata": {},
   "source": [
    "## 1. Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ceccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification data\n",
    "X_clf, y_clf = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "feature_names = [f'feature_{i}' for i in range(X_clf.shape[1])]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd476175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification metrics summary\n",
    "metrics = classification_summary(y_test, y_pred)\n",
    "print(\"Classification Metrics:\")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b82b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    y_test, y_pred,\n",
    "    labels=['Negative', 'Positive'],\n",
    "    title='Confusion Matrix',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Confusion Matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    y_test, y_pred,\n",
    "    labels=['Negative', 'Positive'],\n",
    "    normalize='true',\n",
    "    title='Normalized Confusion Matrix',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75847093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fig, ax = plot_roc_curve(\n",
    "    y_test, y_proba,\n",
    "    title='ROC Curve',\n",
    "    show_auc=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "fig, ax = plot_precision_recall_curve(\n",
    "    y_test, y_proba,\n",
    "    title='Precision-Recall Curve',\n",
    "    show_ap=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa80b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Curve\n",
    "fig, ax = plot_calibration_curve(\n",
    "    y_test, y_proba,\n",
    "    title='Calibration Curve',\n",
    "    n_bins=10,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe489b17",
   "metadata": {},
   "source": [
    "## 2. Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate regression data\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    noise=20,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train/test split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a regressor\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "print(f\"Training samples: {len(X_train_reg)}\")\n",
    "print(f\"Test samples: {len(X_test_reg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f81d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics summary\n",
    "metrics_reg = regression_summary(y_test_reg, y_pred_reg)\n",
    "print(\"Regression Metrics:\")\n",
    "display(metrics_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abe65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted\n",
    "fig, ax = plot_prediction_error(\n",
    "    y_test_reg, y_pred_reg,\n",
    "    title='Actual vs Predicted',\n",
    "    show_r2=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals Plot\n",
    "fig, ax = plot_residuals(\n",
    "    y_test_reg, y_pred_reg,\n",
    "    title='Residuals vs Predicted',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba785b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Distribution\n",
    "fig, axes = plot_residual_distribution(\n",
    "    y_test_reg, y_pred_reg,\n",
    "    title='Residual Analysis',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d6f8d",
   "metadata": {},
   "source": [
    "## 3. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa27cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "fig, ax = plot_feature_importance(\n",
    "    clf.feature_importances_,\n",
    "    feature_names=feature_names,\n",
    "    top_n=15,\n",
    "    title='Feature Importance (Random Forest)',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2306e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance as dict\n",
    "importance_dict = dict(zip(feature_names, clf.feature_importances_))\n",
    "\n",
    "fig, ax = plot_feature_importance(\n",
    "    importance_dict,\n",
    "    top_n=10,\n",
    "    title='Top 10 Features',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fea2d2",
   "metadata": {},
   "source": [
    "## 4. Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd860168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "fig, ax = plot_learning_curve(\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42),\n",
    "    X_clf, y_clf,\n",
    "    cv=5,\n",
    "    title='Learning Curve',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da44c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve (hyperparameter tuning)\n",
    "fig, ax = plot_validation_curve(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    X_clf, y_clf,\n",
    "    param_name='n_estimators',\n",
    "    param_range=[10, 25, 50, 75, 100],\n",
    "    cv=3,\n",
    "    title='Validation Curve: n_estimators',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328e7cf",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple models using ROC curves\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "}\n",
    "\n",
    "# Train and get probabilities\n",
    "model_probas = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    model_probas[name] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC curves for all models\n",
    "fig, ax = plot_roc_curve(\n",
    "    y_test, model_probas,\n",
    "    title='Model Comparison: ROC Curves',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d483dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR Curves comparison\n",
    "fig, ax = plot_precision_recall_curve(\n",
    "    y_test, model_probas,\n",
    "    title='Model Comparison: Precision-Recall Curves',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e56c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration comparison\n",
    "fig, ax = plot_calibration_curve(\n",
    "    y_test, model_probas,\n",
    "    title='Model Comparison: Calibration',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff114a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Classification metrics and visualizations\n",
    "- Regression metrics and residual analysis\n",
    "- Feature importance plots\n",
    "- Learning and validation curves\n",
    "- Model comparison techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
